# CodeCamp2017
Presentations from Boston and NYC

In these projects you will find examples of use of the MixedRealityToolkit to react to gestures and input from the user, including voice, gaze, and touch.

Note: Arts assets are created by me. Please do not distribute without permission :)
